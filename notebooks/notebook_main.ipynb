{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook to help the main come to life "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## IMPORTS ##########\n",
    "\n",
    "# common\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OTSU\n",
    "from skimage.filters import threshold_otsu \n",
    "\n",
    "# filtering \n",
    "from scipy.ndimage import uniform_filter\n",
    "from skimage.measure import label, regionprops \n",
    "\n",
    "# shapefile_to_mask\n",
    "import geopandas as gpd\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "# test & display\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BANDS RECUPERATION ##\n",
    "\n",
    "# TODO\n",
    "\n",
    "# === paths to both imagess ===\n",
    "\n",
    "path_img1 = r\"C:\\Users\\gbonlieu\\Documents\\herramienta\\change_detection_tool\\data\\preprocessed\\t6\\t6_pre_sigma.tif\"\n",
    "path_img2 = r\"C:\\Users\\gbonlieu\\Documents\\herramienta\\change_detection_tool\\data\\preprocessed\\t6\\t6_post_sigma.tif\"\n",
    "\n",
    "# === bands reading and opening  === \n",
    "\n",
    "with rasterio.open(path_img1) as src1:  # pre image  \n",
    "    img1 = src1.read()         # shape = (nb_bands, height, width)\n",
    "    profile1 = src1.profile    # metadata \n",
    "\n",
    "with rasterio.open(path_img2) as src2: # post image\n",
    "    img2 = src2.read()\n",
    "    profile2 = src2.profile\n",
    "\n",
    "## TODO \n",
    "\n",
    "# Tests \n",
    "\n",
    "# === quick print for verification ===\n",
    "print(\"Image 1 :\", img1.shape, \"bands =\", profile1[\"count\"])\n",
    "print(\"Image 2 :\", img2.shape, \"bands =\", profile2[\"count\"])\n",
    "print(\"Number of NaN :\", np.isnan(img1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## NODATA HANDLING ##########\n",
    " \n",
    "def to_nan(arr: np.ndarray, nodata_values=(-9999, -32768, -3.4028235e38)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Replace NoData values by NaN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray\n",
    "        Input array (any dtype).\n",
    "    nodata_values : tuple of numbers, optional\n",
    "        Values to treat as NoData and convert to NaN.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Float32 array with the same shape as `arr`, where all nodata_values\n",
    "        have been replaced by NaN.\n",
    "    \"\"\"\n",
    "    out = arr.astype(\"float32\", copy=True) # we cast to float32 so that NaN is representable\n",
    "\n",
    "    for nd in nodata_values:\n",
    "        np.putmask(out, out == nd, np.nan) # np.putmask(array, mask, value) replaces array[mask] by value\n",
    "\n",
    "    return out\n",
    "\n",
    "# TODO \n",
    "\n",
    "img1=to_nan(img1)\n",
    "img2=to_nan(img2)\n",
    "\n",
    "# TODO  \n",
    "\n",
    "# Tests \n",
    "\n",
    "# === quick print for verification ===\n",
    "print(\"Image 1 :\", img1.shape, \"bands =\", profile1[\"count\"])\n",
    "print(\"Image 2 :\", img2.shape, \"bands =\", profile2[\"count\"])\n",
    "print(\"Number of NaN :\", np.isnan(img1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## DIMENSIONS ALIGNMENT BY PADDING ##########\n",
    "\n",
    "\n",
    "def pad_right(img: np.ndarray, ncols: int = 1, fill_value: float = np.nan) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Add one or several columns of pixels to the RIGHT side of an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        3D (C, H, W) image (even if one band with rasterio opening 3D image with C=1)\n",
    "    ncols : int, optional\n",
    "        Number of columns to add (default 1).\n",
    "    fill_value : float, optional\n",
    "        Value used to fill the new pixels (NaN by default).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        New image with `ncols` extra columns on the right.\n",
    "    \"\"\"\n",
    "    if img.ndim == 3:\n",
    "        C, H, W = img.shape\n",
    "        pad_width = ((0, 0), (0, 0), (0, ncols)) # padding on width axis only: (C), (H), (W)\n",
    "    else:\n",
    "        raise ValueError(\"img must be 3D (C, H, W)\")\n",
    "\n",
    "    img_padded = np.pad(img, pad_width=pad_width, mode=\"constant\", constant_values=fill_value)\n",
    "\n",
    "    return img_padded\n",
    "\n",
    "\n",
    "def pad_bottom(img: np.ndarray, nrows: int = 1, fill_value: float = np.nan) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Add one or several rows of pixels at the BOTTOM of an image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        3D (C, H, W) image (even if one band with rasterio opening 3D image with C=1)\n",
    "    nrows : int, optional\n",
    "        Number of rows to add (default 1).\n",
    "    fill_value : float, optional\n",
    "        Value used to fill the new pixels (NaN by default).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        New image with `nrows` extra rows at the bottom.\n",
    "    \"\"\"\n",
    "    if img.ndim == 3:\n",
    "        C, H, W = img.shape\n",
    "        pad_width = ((0, 0), (0, nrows), (0, 0)) # padding on height axis only: (C), (H), (W)\n",
    "    else:\n",
    "        raise ValueError(\"img must 3D (C, H, W)\")\n",
    "\n",
    "    img_padded = np.pad(img, pad_width=pad_width, mode=\"constant\", constant_values=fill_value)\n",
    "    \n",
    "    return img_padded\n",
    "\n",
    "\n",
    "def align_by_padding(img1: np.ndarray, profile1: dict, img2: np.ndarray, profile2: dict, fill_value: float = np.nan, check_max_diff: bool = True) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Align two images by adding columns (to the RIGHT) and/or rows (at the BOTTOM) to the smaller one so that both have the same size (H, W).\n",
    "\n",
    "    We do not modify the profile here, otherwise we would also have to update\n",
    "    the affine transform, which is not trivial . Later in the pipeline we will crop back to the original size to retrurn to img1's format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img1 : np.ndarray     First image (2D or 3D).\n",
    "    profile1 : dict       Rasterio profile for the first image.\n",
    "    img2 : np.ndarray     Second image (2D or 3D).\n",
    "    profile2 : dict       Rasterio profile for the second image.\n",
    "    fill_value : float, optional      Value used for padding (NaN by default).\n",
    "    check_max_diff : bool, optional   If True, raise an error if the initial height/width difference is greater than 1 row or 1 column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    img1_out : np.ndarray First image after padding (if any).\n",
    "    img2_out : np.ndarray Second image after padding (if any).\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- Check that the two profiles are identical EXCEPT for keys directly or indirectly related to size -----\n",
    "\n",
    "    keys_to_ignore = {\"transform\", \"height\", \"width\", \"blockxsize\", \"blockysize\"}\n",
    "\n",
    "    for key in profile1:\n",
    "        if key in keys_to_ignore:\n",
    "            continue  # skips directly to the next key\n",
    "        if key not in profile2:\n",
    "            raise ValueError(\n",
    "                f\"[ERROR] align_by_padding: key '{key}' is missing in the second profile.\")\n",
    "        if profile1[key] != profile2[key]:\n",
    "            raise ValueError(\n",
    "                f\"[ERROR] align_by_padding: profiles differ on key '{key}'.\\n\"\n",
    "                f\"profile1[{key!r}] = {profile1[key]!r}\\n\"\n",
    "                f\"profile2[{key!r}] = {profile2[key]!r}\\n\"\n",
    "                \"Images are not spatially compatible for spatial alignment.\"\n",
    "            )\n",
    "\n",
    "    # ----- Helper to get current H, W -----\n",
    "    def hw(arr: np.ndarray) -> tuple[int, int]:\n",
    "        return arr.shape[-2], arr.shape[-1]  # (H, W)\n",
    "\n",
    "    H1, W1 = hw(img1)\n",
    "    H2, W2 = hw(img2)\n",
    "\n",
    "    # Differences (positive => img2 larger than img1)\n",
    "    dH = H2 - H1\n",
    "    dW = W2 - W1\n",
    "\n",
    "    if check_max_diff and (abs(dH) > 1 or abs(dW) > 1):\n",
    "        raise ValueError(f\"Size difference greater than 1 row/column: dH={dH}, dW={dW}\")\n",
    "\n",
    "    img1_out, img2_out = img1, img2\n",
    "\n",
    "    # ----- Align height (rows): pad at the BOTTOM -----\n",
    "    if dH > 0:\n",
    "        # img1 is smaller in H -> pad img1\n",
    "        img1_out = pad_bottom(img1_out, nrows=dH, fill_value=fill_value)\n",
    "        H1 = H2  \n",
    "    elif dH < 0:\n",
    "        # img2 is smaller in H -> pad img2\n",
    "        img2_out = pad_bottom(img2_out, nrows=-dH, fill_value=fill_value)\n",
    "        H2 = H1  \n",
    "\n",
    "    # ----- Align width (columns): pad to the RIGHT -----\n",
    "    if dW > 0:\n",
    "        # img1 is smaller in W -> pad img1\n",
    "        img1_out = pad_right(img1_out, ncols=dW, fill_value=fill_value)\n",
    "        W1 = W2\n",
    "    elif dW < 0:\n",
    "        # img2 is smaller in W -> pad img2\n",
    "        img2_out = pad_right(img2_out, ncols=-dW, fill_value=fill_value)\n",
    "        W2 = W1\n",
    "\n",
    "    return img1_out, img2_out\n",
    "\n",
    "\n",
    "\n",
    "# TODO \n",
    "\n",
    "img1, img2 = align_by_padding(img1, profile1, img2, profile2)\n",
    "\n",
    "# TODO  \n",
    "\n",
    "# Tests \n",
    "\n",
    "# === quick print for verification ===\n",
    "print(\"Image 1 :\", img1.shape, \"bands =\", profile1[\"count\"])\n",
    "print(\"Image 2 :\", img2.shape, \"bands =\", profile2[\"count\"])\n",
    "print(\"Number of NaN :\", np.isnan(img1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CLIPPING AND NORMALIZATION OF BANDS ########## \n",
    "\n",
    "def clip_percentiles(img: np.ndarray, p_low: float = 1, p_high: float = 99) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Clips extreme values of each band between percentiles p_low and p_high.\n",
    "    Input: array (nb_bands, height, width)\n",
    "    Output: array of the same shape\n",
    "    Handles NaN values\n",
    "    \"\"\"\n",
    "    out = np.empty_like(img, dtype=float)\n",
    "\n",
    "    for i in range(img.shape[0]):\n",
    "        band = img[i]\n",
    "        low = np.nanpercentile(band, p_low)\n",
    "        high = np.nanpercentile(band, p_high)\n",
    "        out[i] = np.clip(band, low, high)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def normalize_band(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalizes a SINGLE band.\n",
    "    Handles NaN values\n",
    "    \"\"\"\n",
    "    arr_min = np.nanmin(arr)\n",
    "    arr_max = np.nanmax(arr)\n",
    "\n",
    "    if arr_max == arr_min:\n",
    "        return np.zeros_like(arr, dtype=float)\n",
    "\n",
    "    return (arr - arr_min) / (arr_max - arr_min)\n",
    "\n",
    "\n",
    "def normalize_image(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize a multi-band image: calls normalize_band independently for each band (otherwise we would normalize different bands at the same time)\n",
    "    \"\"\"\n",
    "    img_norm = np.empty_like(img, dtype=float) # creates empty image of same shape\n",
    "    for i in range(img.shape[0]):\n",
    "        img_norm[i] = normalize_band(img[i])\n",
    "    return img_norm\n",
    "\n",
    "## TODO \n",
    "\n",
    "img1 = normalize_image(clip_percentiles(img1))\n",
    "img2 = normalize_image(clip_percentiles(img2))\n",
    "\n",
    "## TODO \n",
    "\n",
    "# Test \n",
    "\n",
    "val_min = np.nanmin(img1) \n",
    "val_max = np.nanmax(img1)\n",
    "print(f\"Value min : {val_min}\")\n",
    "print(f\"Value max : {val_max}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## DISSIMILARITY MATRIX ##########\n",
    "\n",
    "def dissimilarity(img1: np.ndarray, img2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Gives a similarity index between two images between 0 and 1,\n",
    "    where 1 = very similar pixels, and 0 = very different pixels\n",
    "    \"\"\"\n",
    "\n",
    "    # Basic verification\n",
    "    if img1.shape != img2.shape:\n",
    "        raise ValueError(\"Both images must have the same shape (bands, height, width)\")\n",
    "\n",
    "    # Vectorized computation of the Euclidean distance\n",
    "    dist = np.sqrt(np.sum((img1 - img2) ** 2, axis=0))  # sum over the band axis -> for each pixel we compute Euclidean distance between the vectors formed by band values\n",
    "    dist = dist / (np.sqrt(img1.shape[0])+1)  # if Euclidean distance is 0, dissimilarity = 0, if it is sqrt(nb of bands) (maximum by Pythagorean theorem), dissimilarity = 1\n",
    "    return dist\n",
    "\n",
    "## TODO\n",
    "\n",
    "dist=dissimilarity(img1, img2)\n",
    "\n",
    "## TODO\n",
    "\n",
    "# Test\n",
    "\n",
    "\n",
    "val_min = np.nanmin(dist)  # possible to get 0 even with a lot of bands, if all bands or almost all contain NaNs for certain pixels and same values on the remaining bands\n",
    "val_max = np.nanmax(dist)\n",
    "print(f\"Value min : {val_min}\")\n",
    "print(f\"Value max : {val_max}\")\n",
    "print(\"Number of NaN :\", np.isnan(dist).sum())\n",
    "\n",
    "figdist, axdist = plt.subplots(figsize=(7,5))\n",
    "imgdist = axdist.imshow(dist, cmap=\"gray\")\n",
    "axdist.set_title(\"Dissimilarity\")\n",
    "figdist.colorbar(imgdist, ax=axdist, label=\"Pixel values\")\n",
    "\n",
    "path_img1 = r\"C:\\Users\\gbonlieu\\Documents\\herramienta\\change_detection_tool\\data\\preprocessed\\t6\\t6_pre_sigma.tif\"\n",
    "output_path = r\"C:\\Users\\gbonlieu\\Documents\\herramienta\\explore\\dis.tif\"\n",
    "with rasterio.open(path_img1) as src1:\n",
    "        img1 = src1.read()\n",
    "        profile1 = src1.profile\n",
    "with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "    # On multiplie par 255 si 'final' est entre 0 et 1, puis on convertit\n",
    "    data_to_write = (dist * 255).astype('uint8')\n",
    "    dst.write(data_to_write, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## TILING ##########\n",
    "\n",
    "\n",
    "def tile_image_2d(img2d: np.ndarray, n: int, fill_value=np.nan):\n",
    "    \"\"\"\n",
    "    Découpe une image 2D (H, W) en n x n tuiles de taille égale.\n",
    "    Si H ou W ne sont pas multiples de n, on pad avec `fill_value` (en bas/droite), \n",
    "    ceci implique que la qualité de l'analyse sur le bord droit et le bord bas est très fortement altérée\n",
    "\n",
    "    Retour:\n",
    "      tiles : np.ndarray de shape (n, n, tile_height, tile_width)\n",
    "      meta  : dict avec infos (tile_height, tile_width, pad_bottom, pad_right)\n",
    "    \"\"\"\n",
    "    assert img2d.ndim == 2, \"img2d doit être 2D (H, W).\"\n",
    "    H, W = img2d.shape\n",
    "\n",
    "    # Tailles de tuiles (on prend ceil pour ne rien perdre → padding si nécessaire)\n",
    "    tile_height = int(np.ceil(H / n))\n",
    "    tile_width = int(np.ceil(W / n))\n",
    "\n",
    "    # Dimensions padées pour tomber exactement sur n * tile\n",
    "    H_pad = tile_height * n\n",
    "    W_pad = tile_width * n\n",
    "    pad_bottom = H_pad - H\n",
    "    pad_right  = W_pad - W\n",
    "\n",
    "    # Padding bas/droite\n",
    "    img_pad = np.pad(img2d,\n",
    "                     pad_width=((0, pad_bottom), (0, pad_right)),\n",
    "                     mode=\"constant\",\n",
    "                     constant_values=fill_value)\n",
    "\n",
    "    # Reshape → (n, tile_height, n, tile_width) puis permute → (n, n, tile_height, tile_width)  objectif tiles[i;j] → images 2D taille (tile_height, tile_width)\n",
    "\n",
    "    tiles = img_pad.reshape(n, tile_height, n, tile_width).transpose(0, 2, 1, 3)\n",
    "    meta = dict(tile_height=tile_height, tile_width=tile_width, pad_bottom=pad_bottom, pad_right=pad_right) # dictionnaire plus pratique pour la reconstruction \n",
    "\n",
    "    return tiles, meta\n",
    "\n",
    "## TODO \n",
    "\n",
    "tiles, meta = tile_image_2d(dist, 1)\n",
    "\n",
    "## TODO \n",
    "\n",
    "\n",
    "# Test\n",
    "\n",
    "tile11 = tile_image_2d(dist, 10)[0][0,0]\n",
    "figtile1, axtile1 = plt.subplots(figsize=(7,5))  \n",
    "imgtile1=axtile1.imshow(tile11, cmap=\"gray\") # \n",
    "axtile1.set_title(\"Dissimilarity tile 11\")\n",
    "figtile1.colorbar(imgtile1, ax=axtile1, label=\"Pixel Values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## THRESHOLDING ##########\n",
    "\n",
    "def otsu_tile(img: np.ndarray, k: float = 1.0, nan_as_bg: bool = True, foreground: str = \"high\"):\n",
    "    \"\"\"\n",
    "    Global Otsu on a 2D image (values expected in [0, 1]).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        2D image. NaN allowed.\n",
    "    k : float\n",
    "        Threshold scaling factor.\n",
    "    nan_as_bg : bool\n",
    "        If True, NaN become background in the final mask (background).\n",
    "        If False, NaN become object in the final mask (foreground).\n",
    "    foreground : {\"high\", \"low\"}\n",
    "        \"high\"  -> pixels > threshold are set to 1 ; \"low\" -> pixels <= threshold are set to 1.\n",
    "        Here we consider \"change\" as the object, so usually \"high\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask : np.ndarray bool\n",
    "        Binary mask.\n",
    "    thr : float\n",
    "        Otsu threshold computed on finite values.\n",
    "    \"\"\"\n",
    "    if img.ndim != 2:\n",
    "        raise ValueError(\"Image must be 2D\")\n",
    "\n",
    "    # valid values to estimate the threshold\n",
    "    valid = img[np.isfinite(img)]\n",
    "    if valid.size == 0:\n",
    "        # all NaN: no usable threshold\n",
    "        raise ValueError(\"Cannot compute Otsu threshold: the image contains only NaN values.\")\n",
    "    \n",
    "    vmin, vmax = float(valid.min()), float(valid.max())\n",
    "    if vmin == vmax:\n",
    "        # degenerate case: all identical -> threshold = that value\n",
    "        thr = vmin\n",
    "    else:\n",
    "        thr = k * float(threshold_otsu(valid))\n",
    "\n",
    "    if foreground == \"high\":\n",
    "        mask = img >= thr\n",
    "    elif foreground == \"low\":\n",
    "        mask = img <= thr\n",
    "    else:\n",
    "        raise ValueError(\"foreground must be 'high' or 'low'\")\n",
    "\n",
    "    if nan_as_bg:\n",
    "        mask = np.where(np.isfinite(img), mask, False)  # np.where(condition, value_if_true, value_if_false)\n",
    "        # more functional (steps more readable, debugging easier) than an in-place transform like np.putmask(mask, ~np.isfinite(img), False)\n",
    "        # if nan_as_bg is False, then nodata (a non-zero value) becomes True so it is considered as object\n",
    "\n",
    "    return mask.astype(bool), thr\n",
    "\n",
    "\n",
    "\n",
    "def apply_otsu_to_tiles(tiles: np.ndarray, k: float = 1.0, *, nan_as_bg: bool = True, foreground: str = \"high\"):\n",
    "    \"\"\"\n",
    "    Apply otsu_tile on each tile of an array (n, n, tile_h, tile_w)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    masks : (n, n, tile_h, tile_w) bool: Binary mask for each tile\n",
    "    thr_grid : (n, n) float32: Threshold per tile\n",
    "    \"\"\"\n",
    "    if tiles.ndim != 4:\n",
    "        raise ValueError(\"tiles must have shape (n_rows, n_cols, tile_h, tile_w)\")\n",
    "\n",
    "    n_r, n_c, th, tw = tiles.shape\n",
    "    masks = np.empty_like(tiles, dtype=bool)\n",
    "    thr_grid = np.empty((n_r, n_c), dtype=np.float32)\n",
    "\n",
    "    for i in range(n_r):\n",
    "        for j in range(n_c):\n",
    "            m, thr = otsu_tile(tiles[i, j], k, nan_as_bg=nan_as_bg, foreground=foreground)\n",
    "            masks[i, j] = m\n",
    "            thr_grid[i, j] = thr\n",
    "\n",
    "    return masks, thr_grid\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TODO\n",
    "\n",
    "masks, thr_grid = apply_otsu_to_tiles(tiles)\n",
    "\n",
    "## TODO \n",
    "\n",
    "# Test\n",
    "\n",
    "\n",
    "tile11s, thr = otsu_tile(tile11)\n",
    "print(f\"Thresholds : {thr_grid}\")\n",
    "figtile1s, axtile1s = plt.subplots(figsize=(7,5))  \n",
    "imgtile1s=axtile1s.imshow(tile11s, cmap=\"gray\") # \n",
    "axtile1s.set_title(\"Dissimilarity tile 11 thresholded\")\n",
    "figtile1s.colorbar(imgtile1s, ax=axtile1s, label=\"Pixel values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## REASSEMBLY ##########\n",
    "\n",
    "def assemble_tiles_to_image(masks_4d: np.ndarray, meta: dict | None = None) -> np.ndarray:  # meta: dict | None = None, this notation is possible since python 3.11\n",
    "    \"\"\"\n",
    "    Stitches a 4D array (n_rows, n_cols, tile_h, tile_w) back into a single 2D image.\n",
    "\n",
    "    If `meta` is provided (with pad_bottom and pad_right), the padding added during tiling is removed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    masks_4d : np.ndarray bool\n",
    "        One mask (2D array) per tile, shape: (n_rows, n_cols, tile_h, tile_w)\n",
    "    meta : dict, optional\n",
    "        Dictionary returned by tile_image_2d, dict(tile_height=tile_height, tile_width=tile_width,\n",
    "        pad_bottom=pad_bottom, pad_right=pad_right)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask_2d : np.ndarray bool\n",
    "        Global 2D mask (without padding if meta is provided)\n",
    "    \"\"\"\n",
    "    if masks_4d.ndim != 4:\n",
    "        raise ValueError(\"masks_4d must have shape (n_rows, n_cols, tile_h, tile_w)\")\n",
    "\n",
    "    n_r, n_c, tile_h, tile_w = masks_4d.shape\n",
    "\n",
    "    # Put tiles back in original order so they can be merged with reshape\n",
    "    mask_padded = masks_4d.transpose(0, 2, 1, 3).reshape(n_r * tile_h, n_c * tile_w)\n",
    "\n",
    "    # Remove padding if meta is provided\n",
    "    if meta is not None:\n",
    "        pad_bottom = int(meta.get(\"pad_bottom\", 0))  # meta.get(\"pad_bottom\", 0) reads the value if it exists, else 0 by default (no padding)\n",
    "        pad_right = int(meta.get(\"pad_right\", 0))    # same here\n",
    "        if pad_bottom or pad_right:  # If at least one of the two is non-zero, we crop\n",
    "            mask_padded = mask_padded[: mask_padded.shape[0] - pad_bottom,\n",
    "                                      : mask_padded.shape[1] - pad_right]\n",
    "\n",
    "    return mask_padded.astype(bool)\n",
    "\n",
    "\n",
    "## TODO\n",
    "\n",
    "final = assemble_tiles_to_image(masks, meta)\n",
    "\n",
    "## TODO \n",
    "\n",
    "# Tests\n",
    "\n",
    "figfin, axfin = plt.subplots(figsize=(7,5))  \n",
    "imgfin=axfin.imshow(final, cmap=\"gray\") # \n",
    "axfin.set_title(\"Final\")\n",
    "figfin.colorbar(imgfin, ax=axfin, label=\"Pixel values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## FILTERING ##########\n",
    "\n",
    "\n",
    "\n",
    "def filter_dense_regions(mask: np.ndarray,\n",
    "                          win_size: int = 30,\n",
    "                          d: float = 0.5,\n",
    "                          min_area: int = 3000, closing: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Filters a binary mask to keep only the zones:\n",
    "      - located in a locally dense white region\n",
    "      - with a sufficient size (minimum area)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : np.ndarray bool 0/1\n",
    "        Binary image (True/1 = white).\n",
    "    win_size : int\n",
    "        Size of the side square window for local density computation (in pixels), if win_size even a convention is used to center the pixel in the window.\n",
    "    d : float\n",
    "        Minimum density of white in the window (0-1).\n",
    "    min_area : int\n",
    "        Minimum area (in pixels) for kept connected components.\n",
    "    closing : bool\n",
    "        If True, keep only pixels both dense AND originally white.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filt : np.ndarray bool\n",
    "        Filtered binary mask.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure we have a float 0/1 array\n",
    "    mask_float = mask.astype(float)\n",
    "\n",
    "    # 1) Local density of white in a window of size win_size\n",
    "    # mode=\"nearest\" avoids border artifacts by duplicating edge pixels\n",
    "    local_mean = uniform_filter(mask_float, size=win_size, mode=\"nearest\")\n",
    "    dense_mask = local_mean >= d  # pixels inside a dense zone\n",
    "\n",
    "    # Optionally restricts to pixels originally white\n",
    "    if closing:\n",
    "        core = dense_mask & (mask_float > 0.5)\n",
    "    else: core = dense_mask\n",
    "\n",
    "    # 2) Filter by connected-component size\n",
    "    labels = label(core, connectivity=2)  # label() converts binary mask in connected components, 8-neighborhood (diagonals included)\n",
    "    filt = np.zeros_like(labels, dtype=np.uint8)  # GeoTIFF does not support native boolean → convert to uint8\n",
    "\n",
    "    for region in regionprops(labels):  # regionprops analyses each connected component of label\n",
    "        if region.area >= min_area:     # region.area = number of pixels in the connected component\n",
    "            filt[labels == region.label] = True  # region.label = ID of the region\n",
    "\n",
    "    return filt\n",
    "\n",
    "## TODO\n",
    "\n",
    "filt = filter_dense_regions(final, 30, 0.5, 3000, closing=False)\n",
    "\n",
    "## TODO \n",
    "\n",
    "# Tests\n",
    "\n",
    "figfilt, axfilt = plt.subplots(figsize=(7,5))  \n",
    "imgfilt=axfilt.imshow(filt, cmap=\"gray\") # \n",
    "axfilt.set_title(\"Filtered\")\n",
    "figfilt.colorbar(imgfilt, ax=axfilt, label=\"Pixel values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MAIN_DTOD_0 ##########\n",
    " \n",
    "def main_dtod_0(path_img1: str, path_img2: str, n: int, k: float = 1.0, closing: bool = False, p: int = 30, d: float = 0.5, a: int = 4000, out_path: str | None = None) -> tuple[dict, np.ndarray]:\n",
    "    \"\"\"\n",
    "    ...\n",
    "    If out_path is not None, writes the raster at the given path out_path\n",
    "    \"\"\"\n",
    "\n",
    "    # ==== bands loading ====\n",
    "\n",
    "    with rasterio.open(path_img1) as src1:\n",
    "        img1 = src1.read()\n",
    "        profile1 = src1.profile\n",
    "\n",
    "    with rasterio.open(path_img2) as src2:\n",
    "        img2 = src2.read()\n",
    "        profile2 = src2.profile\n",
    "\n",
    "    # ==== NaN handling, padding, clipping and normalization ====\n",
    "\n",
    "    img1 = to_nan(img1)\n",
    "    img2 = to_nan(img2)\n",
    "    img1, img2 = align_by_padding(img1, profile1, img2, profile2)\n",
    "\n",
    "    img1 = normalize_image(clip_percentiles(img1))\n",
    "    img2 = normalize_image(clip_percentiles(img2))\n",
    "\n",
    "    # ==== dissimilarity computation ====\n",
    "\n",
    "    dist = dissimilarity(img1, img2)\n",
    "\n",
    "    # ==== tiling, thresholding and reassembly ====\n",
    "\n",
    "    tiles, meta = tile_image_2d(dist, n)\n",
    "\n",
    "    masks, thr_grid = apply_otsu_to_tiles(tiles, k)\n",
    "\n",
    "    final = assemble_tiles_to_image(masks, meta)\n",
    "\n",
    "    # ==== filtering ====\n",
    "\n",
    "    filt = filter_dense_regions(final, p, d, a, closing)\n",
    "\n",
    "    # We return to the initial size so that it matches the affine transform of the profile, which would be hard to update correctly; and we update the rest of the profile\n",
    "\n",
    "    H1 = profile1[\"height\"]\n",
    "    W1 = profile1[\"width\"]\n",
    "    \n",
    "    filt = filt[:H1, :W1]\n",
    "\n",
    "    profile = profile1.copy()\n",
    "    profile.update(dtype=\"uint8\", nodata=0, count=1)   # update only what changed in the profile\n",
    "\n",
    "    # ==== writing ====\n",
    "\n",
    "    if out_path is not None:\n",
    "        with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "            dst.write(filt.astype(\"uint8\") * 255, 1)  # ensure we don't write a tif with boolean values directly\n",
    "\n",
    "    return profile, filt\n",
    "\n",
    "\n",
    "\n",
    "# TODO\n",
    "\n",
    "profile, filt = main_dtod_0(path_img1, path_img2, 1, k=1, p=27, d=0.5, a=3000) # out_path=r\"C:\\Users\\gbonlieu\\Documents\\code_python_outil\\outil_detection_changement\\ouputs\\output_vrac\\t3bis_out\\test2.tif\")\n",
    "\n",
    "# TODO\n",
    "\n",
    "# Test\n",
    "\n",
    "print(f\"Height: {main_dtod_0(path_img1, path_img2, 10)[1].shape[-2]}\")\n",
    "pprint(profile)\n",
    "\n",
    "# --- affichage ---\n",
    "fig, axes = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Image filtrée\n",
    "im1 = axes.imshow(filt, cmap=\"gray\")\n",
    "axes.set_title(\"Filtered\")\n",
    "fig.colorbar(im1, ax=axes, label=\"Pixel Values\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## PERFORMANCE METRICS ##########\n",
    "\n",
    "########## SHAPEFILE TO MASK ##########\n",
    "\n",
    "def shapefile_to_mask(shp_path: str, ref_raster_path: str, out_path: str | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Rasterizes a polygon shapefile into a binary mask (0/1),\n",
    "    aligned on a reference raster.\n",
    "\n",
    "    - shp_path : path to the shapefile (polygons)\n",
    "    - ref_raster_path : reference GeoTIFF (size, transform, crs etc)\n",
    "    - out_path : if not None, saves the mask as GeoTIFF using out_path as output file path\n",
    "\n",
    "    Returns: mask (np.ndarray 2D, dtype=uint8)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Read reference raster\n",
    "    with rasterio.open(ref_raster_path) as src:\n",
    "        ref_transform = src.transform\n",
    "        ref_crs = src.crs\n",
    "        out_shape = (src.height, src.width)\n",
    "        profile = src.profile\n",
    "\n",
    "    # 2) Read shapefile\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "\n",
    "    if gdf.empty or gdf.geometry.isna().all() or gdf.geometry.is_empty.all():\n",
    "        raise ValueError(\n",
    "            \"[ERROR] shapefile contains no valid geometry \"\n",
    "            \"(0 entities, null or empty geometries).\"\n",
    "        )\n",
    "\n",
    "    # 3) Ensure both CRS match\n",
    "\n",
    "    if gdf.crs != ref_crs:\n",
    "        raise ValueError(\n",
    "            f\"[ERROR] CRS of shapefile ({gdf.crs}) differs from raster CRS ({ref_crs}).\\n\"\n",
    "            f\"Please reproject your shapefile to ({ref_crs}) before continuing.\"\n",
    "        )\n",
    "\n",
    "    # if we want the code to reproject:\n",
    "        # if gdf.crs != ref_crs:\n",
    "        #     print(\n",
    "        #     f\"[WARNING] Le CRS du shapefile ({gdf.crs}) est différent du CRS du raster ({ref_crs}). \"\n",
    "        #     f\"Reprojection automatique en {ref_crs}.\")\n",
    "        #     gdf = gdf.to_crs(ref_crs)\n",
    "\n",
    "        \n",
    "    # 4) Prepare geometries for rasterization\n",
    "    # each polygon is “burned” with value 1, creation of a tuple [(polygone1, 1), (polygone2, 1), (polygone3, 1), ...] as expected by rasterize()\n",
    "    shapes = [(geom, 1) for geom in gdf.geometry if geom is not None]  # skip None geometries (corrupted or empty polygon)\n",
    "\n",
    "    # 5) Rasterization -> mask 0/1\n",
    "    mask = rasterize(shapes=shapes, out_shape=out_shape, transform=ref_transform, fill=0, dtype=\"uint8\")\n",
    "\n",
    "    # 6) Optional save as GeoTIFF\n",
    "    if out_path is not None:\n",
    "\n",
    "        profile.update(dtype=\"uint8\", count=1, nodata=0)\n",
    "        with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "            dst.write(mask.astype(\"uint8\") * 255, 1)  # multiplies by 255 for visibility, writing on band 1\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "########## METRICS ##########\n",
    "\n",
    "def confusion_from_masks(y_true: np.ndarray, y_pred: np.ndarray) -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Computes TP, TN, FP, FN between two binary masks (0/1 or bool).\n",
    "    y_true : reference mask (ground truth)\n",
    "    y_pred : predicted mask\n",
    "\n",
    "    Shapes must match. If shapes differ, raise an error.\n",
    "    Returns: tp, tn, fp, fn (integers)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Safety check: shapes must match ----\n",
    "\n",
    "    # if y_pred was generated using shapefile_to_mask(shp_path: str, ref_raster_path = path_img1) with path_img1 the first image of the main\n",
    "    # both masks should have the same size\n",
    "\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\n",
    "            f\"[ERROR] Masks have different shapes: y_true{y_true.shape}, y_pred{y_pred.shape}.\"\n",
    "        )\n",
    "\n",
    "    yt = np.asarray(y_true).astype(bool)\n",
    "    yp = np.asarray(y_pred).astype(bool)\n",
    "\n",
    "    tp = np.logical_and(yt, yp).sum()\n",
    "    tn = np.logical_and(~yt, ~yp).sum()\n",
    "    fp = np.logical_and(~yt, yp).sum()\n",
    "    fn = np.logical_and(yt, ~yp).sum()\n",
    "\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def metrics_from_masks(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Returns a dict with accuracy, precision, recall, F1, MCC and Kappa.\n",
    "    \"\"\"\n",
    "\n",
    "    tp, tn, fp, fn = confusion_from_masks(y_true, y_pred)\n",
    "    tp, tn, fp, fn = map(float, (tp, tn, fp, fn))  # avoids int32 overflow, in the computation of denom for instance\n",
    "    total = tp + tn + fp + fn\n",
    "\n",
    "    # avoid division by zero\n",
    "    eps = 1e-9\n",
    "\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall = tp / (tp + fn + eps)\n",
    "    f1 = 2 * precision * recall / (precision + recall + eps)\n",
    "    accuracy = (tp + tn) / (total + eps)\n",
    "\n",
    "    # Matthews Correlation Coefficient\n",
    "    denom_mcc = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn) + eps)\n",
    "    mcc = ((tp * tn) - (fp * fn)) / denom_mcc\n",
    "\n",
    "    # Cohen's Kappa\n",
    "    # po: observed agreement (identical to accuracy)\n",
    "    # pe: expected agreement by chance\n",
    "    po = accuracy\n",
    "    pe = ((tp + fp) * (tp + fn) + (tn + fp) * (tn + fn)) / (total**2 + eps)\n",
    "    kappa = (po - pe) / (1 - pe + eps)\n",
    "\n",
    "    return {\n",
    "        \"tp\": int(tp),\n",
    "        \"tn\": int(tn),\n",
    "        \"fp\": int(fp),\n",
    "        \"fn\": int(fn),\n",
    "        \"mcc\": float(mcc),\n",
    "        \"kappa\": float(kappa),\n",
    "        \"F1\": float(f1),\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"accuracy\": float(accuracy)\n",
    "    }\n",
    "\n",
    "\n",
    "# Tests\n",
    "\n",
    "shp_path = r\"C:\\Users\\gbonlieu\\Documents\\herramienta\\change_detection_tool\\data\\preprocessed\\t9\\t9_grd_truth\\t9_grd_truth.shp\"\n",
    "ref_raster_path = r\"C:\\Users\\gbonlieu\\Documents\\herramienta\\change_detection_tool\\data\\preprocessed\\t9\\pre.tif\"\n",
    "out_path = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\ouputs\\output_vrac\\t3bis_out\\testshp.tif\"\n",
    "\n",
    "truth = shapefile_to_mask(shp_path=shp_path, ref_raster_path=ref_raster_path) # out_path=out_path)\n",
    "nb_whites, nb_blacks = truth.sum(), truth.size - truth.sum()\n",
    "print (f\"Number of whites: {nb_whites}\\nNumber of blacks: {nb_blacks}\")\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "im = ax.imshow(truth,\n",
    "               cmap=\"gray\",\n",
    "               interpolation=\"nearest\",  # pas de lissage\n",
    "               vmin=0, vmax=1)           # valeurs 0/1 bien séparées\n",
    "ax.set_title(\"Truth\")\n",
    "fig.colorbar(im, ax=ax, label=\"Pixel Values\")\n",
    "\n",
    "\n",
    "res = metrics_from_masks(truth, main_dtod_0(path_img1, path_img2, 1, k=1.18, p=25, d=0.38, a=2889)[1])\n",
    "for (k, v) in res.items():\n",
    "    print(k, \":\", v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MAIN_UNION0 ##########\n",
    "\n",
    "\n",
    "def main_union0(\n",
    "    configs: list[dict],\n",
    "    shp_path: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes a list of configurations, applies main_dtod_0 to each one,\n",
    "    checks that all reference images share the same profile, computes the\n",
    "    logical union of all resulting binary masks, then displays and returns\n",
    "    the final output.\n",
    "\n",
    "    Each element of `configs` must contain at least:\n",
    "      - \"path_img1\": str\n",
    "      - \"path_img2\": str\n",
    "      - \"n\": int\n",
    "      - \"k\": float\n",
    "      - \"p\": float\n",
    "      - \"d\": float\n",
    "      - \"a\": float\n",
    "      - \"closing\": bool\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    configs : list[dict]\n",
    "        List of dictionaries describing each run.\n",
    "    shp_path : str\n",
    "        Path to the ground-truth shapefile.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {\n",
    "            \"union_mask\": np.ndarray (uint8, 0/1),\n",
    "            \"metrics\": dict (mcc, f1, precision, recall, accuracy),\n",
    "            \"configs\": list[dict] (the configurations used)\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    if not configs:\n",
    "        raise ValueError(\"The 'configs' list is empty: nothing to process.\")\n",
    "\n",
    "    # --- 1) Rasterize ground truth on the first image ---\n",
    "    first_path_img1 = configs[0][\"path_img1\"]\n",
    "    mask_ref = shapefile_to_mask(\n",
    "        shp_path=shp_path,\n",
    "        ref_raster_path=first_path_img1,\n",
    "    )\n",
    "\n",
    "    # --- 2) Check profiles (CRS, transform, size) ---\n",
    "    ref_profile = None\n",
    "    union_mask_bool = None\n",
    "    params_text_lines = []\n",
    "\n",
    "    for idx, cfg in enumerate(configs, start=1):\n",
    "        path_img1 = cfg[\"path_img1\"]\n",
    "        path_img2 = cfg[\"path_img2\"]\n",
    "        n = cfg[\"n\"]\n",
    "        k = cfg[\"k\"]\n",
    "        p = cfg[\"p\"]\n",
    "        d = cfg[\"d\"]\n",
    "        a = cfg[\"a\"]\n",
    "        closing = cfg[\"closing\"]\n",
    "\n",
    "        # Reference image profile\n",
    "        with rasterio.open(path_img1) as src:\n",
    "            profile = {\n",
    "                \"crs\": src.crs,\n",
    "                \"transform\": src.transform,\n",
    "                \"width\": src.width,\n",
    "                \"height\": src.height,\n",
    "            }\n",
    "\n",
    "        if ref_profile is None:\n",
    "            ref_profile = profile\n",
    "        else:\n",
    "            # Check that all profiles match\n",
    "            if (\n",
    "                profile[\"crs\"] != ref_profile[\"crs\"]\n",
    "                or profile[\"transform\"] != ref_profile[\"transform\"]\n",
    "                or profile[\"width\"] != ref_profile[\"width\"]\n",
    "                or profile[\"height\"] != ref_profile[\"height\"]\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    f\"[ERROR] Profile of image {path_img1} \"\n",
    "                    f\"does not match the reference profile.\\n\"\n",
    "                    f\"Reference profile : {ref_profile}\\n\"\n",
    "                    f\"Current profile   : {profile}\"\n",
    "                )\n",
    "\n",
    "        # --- 3) Apply main_dtod_0 with this configuration ---\n",
    "        result = main_dtod_0(\n",
    "            path_img1,\n",
    "            path_img2,\n",
    "            n,\n",
    "            k=k,\n",
    "            closing=closing,\n",
    "            p=p,\n",
    "            d=d,\n",
    "            a=a,\n",
    "        )[1]  # index 1 assumed to be the filtered binary mask\n",
    "\n",
    "        # Convert to boolean (0/1 → False/True)\n",
    "        mask_bool = (np.asarray(result) != 0)\n",
    "\n",
    "        # --- 4) Logical union of masks ---\n",
    "        if union_mask_bool is None:\n",
    "            union_mask_bool = mask_bool\n",
    "        else:\n",
    "            union_mask_bool = union_mask_bool | mask_bool\n",
    "\n",
    "        # Save one line of text describing this configuration (for the legend)\n",
    "        params_text_lines.append(\n",
    "            f\"Run {idx}: n={n}, k={k:.2f}, p={p:.1f}, d={d:.2f}, a={a:.0f}, closing={closing}\"\n",
    "        )\n",
    "\n",
    "    # --- 5) Convert to uint8 (0/1) ---\n",
    "    union_mask = union_mask_bool.astype(np.uint8)\n",
    "\n",
    "    # --- 6) Compute global metrics on the union mask ---\n",
    "    mets = metrics_from_masks(mask_ref, union_mask)\n",
    "\n",
    "    # --- 7) Display ---\n",
    "    h, w = union_mask.shape\n",
    "    fig, ax = plt.subplots(figsize=(w / 100, h / 100))\n",
    "\n",
    "    im = ax.imshow(union_mask, cmap=\"gray\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Main title\n",
    "    ax.set_title(\"Union of binary masks\", fontsize=11)\n",
    "\n",
    "    # Metrics text\n",
    "    txt_metrics = (\n",
    "        f\"MCC={mets['mcc']:.2f}  \"\n",
    "        f\"F1={mets['F1']:.2f}  \"\n",
    "        f\"P={mets['precision']:.2f}  \"\n",
    "        f\"R={mets['recall']:.2f}  \"\n",
    "        f\"Acc={mets['accuracy']:.2f}\"\n",
    "    )\n",
    "\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        -0.08,\n",
    "        txt_metrics,\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"center\",\n",
    "        va=\"top\",\n",
    "        fontsize=8,\n",
    "    )\n",
    "\n",
    "    # Parameters text\n",
    "    txt_params = \"\\n\".join(params_text_lines)\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        -0.25,\n",
    "        txt_params,\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"center\",\n",
    "        va=\"top\",\n",
    "        fontsize=7,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        \"union_mask\": union_mask,\n",
    "        \"metrics\": mets,\n",
    "        \"configs\": configs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SINGLE TEST & DISPLAY ##########\n",
    "\n",
    "\"\"\"\n",
    "Small test script to run main_dtod_0() on two rasters and print the result.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def test_main_display(path_img1: str, path_img2: str, shp_path: str,\n",
    "                      n: int, k: float = 1.0, closing: bool = False,\n",
    "                      p: int = 30, d: float = 0.5, a: int = 4000, \n",
    "                      out_path: str | None = None):\n",
    "    \"\"\"\n",
    "    Runs main_dtod_0() with the given parameters, computes performance\n",
    "    metrics using the ground-truth shapefile, and displays the\n",
    "    result (binary mask) with the parameters & metrics as annotations.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Compute predicted mask ---\n",
    "    profile, filt = main_dtod_0(path_img1, path_img2,\n",
    "                          n, k=k, closing=closing,\n",
    "                          p=p, d=d, a=a, out_path=out_path)\n",
    "\n",
    "    # --- Load and rasterize ground-truth ---\n",
    "    mask_ref = shapefile_to_mask(shp_path, ref_raster_path=path_img1)\n",
    "\n",
    "    # --- Compute performance metrics ---\n",
    "    mets = metrics_from_masks(mask_ref, filt)\n",
    "\n",
    "    # --- Prepare nice figure ---\n",
    "\n",
    "    w, h = profile['width'], profile['height']\n",
    "    fig, ax = plt.subplots(figsize=((w/100), (h/100)))\n",
    "\n",
    "    im = ax.imshow(filt, cmap=\"gray\")\n",
    "\n",
    "    # --- Title: parameters ---\n",
    "    ax.set_title(\n",
    "        f\"Result mask\\n\\n\"\n",
    "        f\"n={n}, k={k}, p={p}, d={d}, a={a}, closing={closing}\",\n",
    "        fontsize=11\n",
    "    )\n",
    "\n",
    "    # --- Text with metrics ---\n",
    "    txt = (f\"MCC={mets['mcc']:.3f}   \" f\"F1={mets['F1']:.3f}   \" f\"P={mets['precision']:.3f}   \" f\"R={mets['recall']:.3f}   \" f\"Acc={mets['accuracy']:.3f}\" ) # :.3f to display only the first 3 decimal places\n",
    "\n",
    "    ax.text(0.5, -0.08, txt, transform=ax.transAxes, ha=\"center\", va=\"top\", fontsize=10)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Full profile :\")\n",
    "    pprint(profile)\n",
    "\n",
    "\n",
    "path_img1 = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\data\\raw\\testnotebooks\\t3bis\\t3bis_pre_varVV.tif\"\n",
    "path_img2 = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\data\\raw\\testnotebooks\\t3bis\\t3bis_0208_varVV.tif\"\n",
    "shp_path = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\data\\raw\\testnotebooks\\t3bis\\t3bis_grd_truth\\t3bis_grdtruth_0204shp\\t3bis_grdtruth_0204.shp\"\n",
    "out_path = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\ouputs\\output_vrac\\t3bis_out\\main_out.tif\"\n",
    "\n",
    "test_main_display(path_img1, path_img2, shp_path,\n",
    "                  n=1, k=1.27, closing=False, p=27, d=0.35, a=3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 2D TEST & DISPLAY  ##########\n",
    "\n",
    "\n",
    "\n",
    "def test_parametres_2D(\n",
    "    path_img1: str, path_img2: str,\n",
    "    idx1: int,\n",
    "    idx2: int,\n",
    "    list1: list,\n",
    "    list2: list,\n",
    "    closing: bool = False,\n",
    "    n: int = 2,\n",
    "    k: float = 1.15,\n",
    "    p: int = 30,\n",
    "    d: float = 0.5,\n",
    "    a: int = 4000,\n",
    "    shp_path: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Explores all possible combinations of TWO parameters among (n, k, p, d, a).\n",
    "\n",
    "    Variable parameters are selected using their indices:\n",
    "    - 1 -> n (tile size / number of tiles)\n",
    "    - 2 -> k (threshold multiplier)\n",
    "    - 3 -> p (filter parameter p)\n",
    "    - 4 -> d (filter parameter d)\n",
    "    - 5 -> a (minimum area)\n",
    "\n",
    "    idx1, idx2 : integers in [1,5] and must be different\n",
    "    list1, list2 : lists of values tested for these two parameters\n",
    "\n",
    "    Other non-explored parameters:\n",
    "    - default values (n=… k=1.15, p=30, d=0.5, a=4000)\n",
    "    - unless explicitly passed in arguments\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Basic checks ----\n",
    "    if idx1 == idx2:\n",
    "        raise ValueError(\"idx1 and idx2 must be different (from 1 to 5).\")\n",
    "\n",
    "    for idx in (idx1, idx2):\n",
    "        if idx < 1 or idx > 5:\n",
    "            raise ValueError(\"Indices must be between 1 and 5.\")\n",
    "\n",
    "    # ---- Mapping index → parameter name ----\n",
    "    index_to_name = {1: \"n\", 2: \"k\", 3: \"p\", 4: \"d\", 5: \"a\"}\n",
    "\n",
    "    name1 = index_to_name[idx1]\n",
    "    name2 = index_to_name[idx2]\n",
    "\n",
    "    # ---- Base parameter values ----\n",
    "    base_params = {\"n\": n, \"k\": k, \"p\": p, \"d\": d, \"a\": a}\n",
    "\n",
    "    # ---- Ground truth mask (optional) ----\n",
    "    mask_ref = None\n",
    "    if shp_path is not None:\n",
    "        mask_ref = shapefile_to_mask(shp_path=shp_path, ref_raster_path=path_img1)\n",
    "\n",
    "    # ---- Read raster shape for figure geometry ----\n",
    "    with rasterio.open(path_img1) as src:\n",
    "        W = src.width\n",
    "        H = src.height\n",
    "\n",
    "    # ---- Build combination grid (param1, param2) ----\n",
    "    combos = list(itertools.product(list1, list2))\n",
    "    n_combos = len(combos)\n",
    "\n",
    "    # ---- \"Square-like\" grid ----\n",
    "    ncols = len(list2)\n",
    "    nrows = len(list1)\n",
    "\n",
    "    fig, axes = plt.subplots( nrows, ncols, figsize=(ncols * (W / 100), nrows * (H / 100)))\n",
    "    axes = np.array(axes).reshape(nrows, ncols)   # to avoid errors when there is only one row or column, this forces axes to always be a 2D array with the correct shape\n",
    "\n",
    "    # ---- Main loop over combinations ----\n",
    "    for idx, (val1, val2) in enumerate(combos):  # enumerate() lets you iterate over a list while keeping the current index\n",
    "        i = idx // ncols\n",
    "        row = idx // ncols\n",
    "        col = idx % ncols\n",
    "        ax = axes[row, col]\n",
    "\n",
    "        # start with base parameters\n",
    "        params = base_params.copy()\n",
    "        params[name1] = val1\n",
    "        params[name2] = val2\n",
    "\n",
    "        try:\n",
    "            # call main algorithm\n",
    "            result = main_dtod_0( path_img1, path_img2, n=params[\"n\"], k=params[\"k\"], closing=closing, p=params[\"p\"], d=params[\"d\"], a=params[\"a\"], )[1]\n",
    "\n",
    "            im = ax.imshow(result, cmap=\"gray\")\n",
    "\n",
    "            # title with the two explored parameters    \n",
    "            ax.set_title(\n",
    "                f\"{name1}={val1:.2f}, {name2}={val2:.2f}, closing={closing}\",                                  \n",
    "                fontsize=15,\n",
    "            )\n",
    "\n",
    "            # metrics if ground truth provided\n",
    "            if mask_ref is not None:\n",
    "                mets = metrics_from_masks(mask_ref, result)\n",
    "                txt = (\n",
    "                    f\"MCC={mets['mcc']:.3f} \"\n",
    "                    f\"F1={mets['F1']:.3f} \"\n",
    "                    f\"P={mets['precision']:.3f} \"\n",
    "                    f\"R={mets['recall']:.3f} \"\n",
    "                    f\"Acc={mets['accuracy']:.3f} \"\n",
    "                )\n",
    "                ax.text(0.5, 0.-0.08, txt, transform=ax.transAxes, ha=\"center\", va=\"top\", fontsize=15)\n",
    "\n",
    "        except Exception as e:\n",
    "            # display error message for this combination\n",
    "            print(\"\\n=== ERROR DURING PARAMETER COMBINATION ===\")\n",
    "            print(\"Message court :\", e)\n",
    "            print(\"\\nTraceback complet :\")\n",
    "            traceback.print_exc() \n",
    "            \n",
    "\n",
    "\n",
    "    # ---- Hide unused axes if grid not full ----\n",
    "    for idx in range(n_combos, nrows * ncols):\n",
    "        row = idx // ncols\n",
    "        col = idx % ncols\n",
    "        axes[row, col].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Tests\n",
    "    \n",
    "path_img1 = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\data\\raw\\testnotebooks\\t3bis\\t3bis_pre_varVV.tif\"\n",
    "path_img2 = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\data\\raw\\testnotebooks\\t3bis\\t3bis_0208_varVV.tif\"\n",
    "shp_path = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\data\\raw\\testnotebooks\\t3bis\\t3bis_grd_truth\\t3bis_grdtruth_0204shp\\t3bis_grdtruth_0204.shp\"\n",
    "list_n = [int(x) for x in np.linspace(1, 7, 7)]\n",
    "list_k = [x for x in np.linspace(1, 1.4, 5)]\n",
    "list_p = [round(x) for x in np.linspace(10, 40, 10)] \n",
    "list_d = [x for x in np.linspace(0.3, 0.55, 5)]\n",
    "list_a = [round(x) for x in np.linspace(500, 4500, 30)]\n",
    "\n",
    "\n",
    "test_parametres_2D(\n",
    "    path_img1,\n",
    "    path_img2,\n",
    "    idx1=4,        \n",
    "    idx2=2,        \n",
    "    list1=list_d,\n",
    "    list2=list_k,\n",
    "    closing=False,\n",
    "    n=1,\n",
    "    p=27.0,\n",
    "    a=2900,\n",
    "    shp_path=shp_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## GRID SEARCH ##########\n",
    "\n",
    "def grid_search_best_params(\n",
    "    path_img1: str,\n",
    "    path_img2: str,\n",
    "    list_n: list[int],\n",
    "    list_k: list[float],\n",
    "    list_p: list[int],\n",
    "    list_d: list[float],\n",
    "    list_a: list[int],\n",
    "    closing: bool = False,\n",
    "    shp_path: str | None = None,\n",
    "    top: int = 3,\n",
    "    mcc_ref: float = 0.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Explores all possible parameter combinations (n, k, p, d, a),\n",
    "    evaluates metrics against ground truth, and:\n",
    "\n",
    "      - returns the top 3 tuples for MCC, precision (with MCC>mcc_ref), recall (with MCC>mcc_ref)\n",
    "      - displays a 3*3 figure: top 3 MCC, top 3 Precision, top 3 Recall\n",
    "\n",
    "    Each subplot shows:\n",
    "      - the binary output of main_dtod(...)\n",
    "      - title: values of n, k, p, d, a\n",
    "      - text under image: MCC, F1, P, R, Acc\n",
    "    \"\"\"\n",
    "\n",
    "    if shp_path is None:\n",
    "        raise ValueError(\"shp_path cannot be None: ground truth is required \")\n",
    "\n",
    "    # ----- 1) Ground truth rasterized on reference image -----\n",
    "    mask_ref = shapefile_to_mask(shp_path=shp_path, ref_raster_path=path_img1)\n",
    "\n",
    "    # ----- 2) Read raster to get dimensions -----\n",
    "    with rasterio.open(path_img1) as src:\n",
    "        w = src.width\n",
    "        h = src.height\n",
    "\n",
    "    # ----- 3) Build combinations -----\n",
    "    all_combos = list(itertools.product(list_n, list_k, list_p, list_d, list_a))\n",
    "\n",
    "    perf = []  # perf is a list of dict, each dict stores params, metrics, result\n",
    "\n",
    "    # ----- 4) Loop over all combinations -----\n",
    "    for (n, k, p, d, a) in all_combos:\n",
    "        try:\n",
    "            # main algorithm call\n",
    "            result = main_dtod_0(\n",
    "                path_img1,\n",
    "                path_img2,\n",
    "                n=n,\n",
    "                k=k,\n",
    "                closing=closing,\n",
    "                p=p,\n",
    "                d=d,\n",
    "                a=a\n",
    "            )[1]\n",
    "\n",
    "            mets = metrics_from_masks(mask_ref, result)\n",
    "\n",
    "            perf.append({\n",
    "                \"params\": {\"n\": n, \"k\": k, \"p\": p, \"d\": d, \"a\": a},\n",
    "                \"metrics\": mets,\n",
    "                \"result\": result,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            # display error message for this combination\n",
    "            print(f\"[WARNING] Skipped combination (n={n}, k={k}, p={p}, d={d}, a={a}) \"\n",
    "                  f\"due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not perf:  # list perf empty\n",
    "        raise RuntimeError(\"No valid combination produced a result.\")\n",
    "\n",
    "    # ----- 5) Sort by each metric -----\n",
    "    def sort_by(metric_name: str):\n",
    "        '''\n",
    "        sorted sorts perf, it needs a key= to know what to compare on \n",
    "        lambda takes a dict r from perf and returns r[\"metrics\"][metric_name] (in our case mcc or precision or recall)\n",
    "        perf is thus sorted by values of metric_name (mcc, precision, recall)\n",
    "        ''' \n",
    "        return sorted(perf, key=lambda r: r[\"metrics\"][metric_name], reverse=True)\n",
    "    \n",
    "    sorted_mcc = sort_by(\"mcc\")\n",
    "    sorted_prec = sort_by(\"precision\")\n",
    "    sorted_rec = sort_by(\"recall\")\n",
    "\n",
    "    # keep top X\n",
    "    top_mcc = sorted_mcc[:top]\n",
    "    top_prec = [r for r in sorted_prec if r[\"metrics\"][\"mcc\"] >= mcc_ref][:top]\n",
    "    top_rec = [r for r in sorted_rec if r[\"metrics\"][\"mcc\"] >= mcc_ref][:top]\n",
    "\n",
    "\n",
    "    # ----- 6) Display figure (3×3: top MCC / top Precision / top Recall) -----\n",
    "    fig, axes = plt.subplots(3, top, figsize=(top * (w / 100), 3 * (h / 100)))\n",
    "\n",
    "    axes = np.atleast_2d(axes)  # ensure 2D even for top=1\n",
    "\n",
    "    def show_row(row_idx: int, selected_results, row_title: str):\n",
    "        '''\n",
    "        displays the result of each line (line 1: mcc, line 2: precision, line 3: recall)\n",
    "        selected_results will thus be top_mcc, top_prec, top_prec\n",
    "        '''\n",
    "        for i, res in enumerate(selected_results):  # enumerate() lets you iterate over a list while keeping the current index\n",
    "            ax = axes[row_idx, i]\n",
    "            img = res[\"result\"]\n",
    "            params = res[\"params\"]\n",
    "            mets = res[\"metrics\"]\n",
    "\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "\n",
    "            ax.set_title(f\"{row_title} #{i+1}\\n\"\n",
    "                f\"n={params['n']}, k={params['k']:.2f}, p={params['p']}, d={params['d']:.2f}, a={params['a']}\",\n",
    "                fontsize=15)\n",
    "\n",
    "            txt = (\n",
    "                f\"MCC={mets['mcc']:.3f} \"\n",
    "                f\"F1={mets['F1']:.3f} \"\n",
    "                f\"P={mets['precision']:.3f} \"\n",
    "                f\"R={mets['recall']:.3f} \"\n",
    "                f\"Acc={mets['accuracy']:.3f}\"\n",
    "            )\n",
    "\n",
    "            ax.text(\n",
    "                0.5,\n",
    "                -0.08,\n",
    "                txt,\n",
    "                transform=ax.transAxes,\n",
    "                ha=\"center\",\n",
    "                va=\"top\",\n",
    "                fontsize=15,\n",
    "            )\n",
    "\n",
    "        # hide empty axes\n",
    "        for j in range(len(selected_results), top):\n",
    "            axes[row_idx, j].axis(\"off\")\n",
    "\n",
    "    show_row(0, top_mcc, \"Top MCC\")\n",
    "    show_row(1, top_prec, \"Top Precision\")\n",
    "    show_row(2, top_rec, \"Top Recall\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ----- 7) Returned values: best tuples -----\n",
    "    return {\"top_mcc\": top_mcc, \"top_precision\": top_prec, \"top_recall\": top_rec}\n",
    "\n",
    "# Tests\n",
    "\n",
    "path_img1 = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\data\\raw\\testnotebooks\\t3bis\\t3bis_pre_varVV.tif\"\n",
    "path_img2 = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\data\\raw\\testnotebooks\\t3bis\\t3bis_0208_varVV.tif\"\n",
    "\n",
    "shp_path = r\"C:\\Users\\gbonlieu\\Documents\\codepythonoutil\\outil_detection_changement\\data\\raw\\testnotebooks\\t3bis\\t3bis_grd_truth\\t3bis_grdtruth_0204shp\\t3bis_grdtruth_0204.shp\"\n",
    "list_n = [int(x) for x in np.linspace(1, 3, 3)]\n",
    "list_k = [x for x in np.linspace(1, 1.4, 5)]\n",
    "list_p = [round(x) for x in np.linspace(20, 40, 4)] \n",
    "list_d = [x for x in np.linspace(0.2, 0.6, 4)]\n",
    "list_a = [round(x) for x in np.linspace(3000, 3000, 1)]\n",
    "\n",
    "best = grid_search_best_params(\n",
    "    path_img1=path_img1,\n",
    "    path_img2=path_img2,\n",
    "    list_n=list_n,\n",
    "    list_k=list_k,\n",
    "    list_p=list_p,\n",
    "    list_d=list_d,\n",
    "    list_a=list_a,\n",
    "    closing=False,\n",
    "    shp_path=shp_path,\n",
    "    top=3,\n",
    "    mcc_ref=0.6\n",
    ")\n",
    "\n",
    "# Example : get the best tuple for MCC\n",
    "best_mcc_1 = best[\"top_mcc\"][0]\n",
    "print(\"Best MCC :\", best_mcc_1[\"metrics\"][\"mcc\"])\n",
    "print(\"Params :\", best_mcc_1[\"params\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vigisar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
