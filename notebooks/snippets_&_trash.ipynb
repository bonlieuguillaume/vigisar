{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8fd7335",
   "metadata": {},
   "source": [
    "# SNIPPETS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30edf78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher plusieurs  images dans une figure \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Exemple de données : 4 matrices 100x100\n",
    "img1 = np.random.rand(100, 100)\n",
    "img2 = np.random.rand(100, 100)\n",
    "img3 = np.random.rand(100, 100)\n",
    "img4 = np.random.rand(100, 100)\n",
    "\n",
    "# Création d'une figure avec 4 sous-figures (axes)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Affichage des images\n",
    "im1 = axes[0, 0].imshow(img1, cmap=\"gray\")\n",
    "axes[0, 0].set_title(\"Image 1\")\n",
    "fig.colorbar(im1, ax=axes[0, 0])\n",
    "\n",
    "im2 = axes[0, 1].imshow(img2, cmap=\"gray\")\n",
    "axes[0, 1].set_title(\"Image 2\")\n",
    "fig.colorbar(im2, ax=axes[0, 1])\n",
    "\n",
    "im3 = axes[1, 0].imshow(img3, cmap=\"gray\")\n",
    "axes[1, 0].set_title(\"Image 3\")\n",
    "fig.colorbar(im3, ax=axes[1, 0])\n",
    "\n",
    "im4 = axes[1, 1].imshow(img4, cmap=\"gray\")\n",
    "axes[1, 1].set_title(\"Image 4\")\n",
    "fig.colorbar(im4, ax=axes[1, 1])\n",
    "\n",
    "# Ajuster les espacements\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ecea9",
   "metadata": {},
   "source": [
    "# Nan-safe instructions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e9190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1) Nettoyage NoData → NaN ----------------------------------------------\n",
    "def to_nan(arr, nodata_values=(-9999, -32768, -3.4028235e38)):\n",
    "    \"\"\"\n",
    "    Remplace les valeurs NoData par NaN.\n",
    "    nodata_values : tuple de valeurs à traiter comme NoData.\n",
    "    Retourne un tableau float (pour pouvoir porter des NaN).\n",
    "    \"\"\"\n",
    "    out = arr.astype('float32', copy=True)\n",
    "    for nd in nodata_values:\n",
    "        np.putmask(out, out == nd, np.nan) # np.putmask(array, mask, value) remplace array[mask] par la value\n",
    "    return out\n",
    "\n",
    "# --- 2) Statistiques robustes (ignorent les NaN) -----------------------------\n",
    "def nan_stats(arr):\n",
    "    \"\"\"\n",
    "    Renvoie un dict avec stats nan-safe.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"min\": float(np.nanmin(arr)),\n",
    "        \"q01\": float(np.nanpercentile(arr, 1)),\n",
    "        \"q05\": float(np.nanpercentile(arr, 5)),\n",
    "        \"median\": float(np.nanmedian(arr)),\n",
    "        \"mean\": float(np.nanmean(arr)),\n",
    "        \"std\": float(np.nanstd(arr)),\n",
    "        \"q95\": float(np.nanpercentile(arr, 95)),\n",
    "        \"q99\": float(np.nanpercentile(arr, 99)),\n",
    "        \"max\": float(np.nanmax(arr)),\n",
    "        \"count_valid\": int(np.isfinite(arr).sum()),\n",
    "        \"count_nan\": int(np.isnan(arr).sum())\n",
    "    }\n",
    "\n",
    "# --- 3) Affichage robuste (stretch percentile + colorbar) --------------------\n",
    "def show_image(arr, title=\"Image\", cmap=\"gray\", p_lo=1, p_hi=99):\n",
    "    \"\"\"\n",
    "    Affiche une image 2D avec colormap et colorbar.\n",
    "    Etale la dynamique entre les percentiles p_lo et p_hi (nan-safe).\n",
    "    \"\"\"\n",
    "    vmin = np.nanpercentile(arr, p_lo)\n",
    "    vmax = np.nanpercentile(arr, p_hi)\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    img = ax.imshow(arr, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(title)\n",
    "    cb = fig.colorbar(img, ax=ax, label=\"Valeurs de pixel\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Remplissage optionnel (à utiliser avec prudence) ---------------------\n",
    "# Si tu dois FORCÉMENT remplacer les NaN par une valeur (p.ex. 0) avant un calcul :\n",
    "# band1_filled = np.nan_to_num(band1_clean, nan=0.0)\n",
    "# Attention : ce choix peut biaiser des moyennes/ratios\n",
    "\n",
    "\n",
    "# --- 4) Exemple d’utilisation ------------------------------------------------\n",
    "# Supposons que `band1` soit ton array d’origine (np.ndarray) lu depuis rasterio.read(1)\n",
    "# band1 = src.read(1)  # à titre d’exemple\n",
    "\n",
    "# 4.1 Nettoyage NoData -> NaN\n",
    "# band1_clean = to_nan(band1, nodata_values=(-9999, -32768))\n",
    "\n",
    "# 4.2 Stats nan-safe\n",
    "# stats = nan_stats(band1_clean)\n",
    "# print(stats)\n",
    "\n",
    "# 4.3 Percentiles spécifiques (nan-safe)\n",
    "# p1, p99 = np.nanpercentile(band1_clean, (1, 99))\n",
    "# print(\"1er percentile:\", p1, \"99e percentile:\", p99)\n",
    "\n",
    "# 4.4 Affichage avec stretch percentile et colorbar\n",
    "# show_image(band1_clean, title=\"Bande 1 (NoData -> NaN)\", cmap=\"gray\", p_lo=1, p_hi=99)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40137e4c",
   "metadata": {},
   "source": [
    "# Difference raster between list of raster tuples (pre, post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ada81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def compute_sar_temporal_differences(list_raster_pairs: list[tuple[str, str]]) -> list[tuple[dict, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Computes the difference between pre and post image pairs for all bands, for all (pre, post) tuples \n",
    "    Includes a metadata consistency check between pre and post images.\n",
    "    \n",
    "    Args:\n",
    "        list_raster_pairs (list of tuples): List containing (pre_path, post_path) strings.\n",
    "        \n",
    "    Returns:\n",
    "        list of tuples: A list of (profile, diff_stack) for each pair.\n",
    "    \"\"\"\n",
    "\n",
    "    diff_images = []\n",
    "\n",
    "    for i, (path_pre, path_post) in enumerate(list_raster_pairs):\n",
    "        with rasterio.open(path_pre) as src_pre, rasterio.open(path_post) as src_post:\n",
    "            \n",
    "            # 1. Shape, crs and S profile check \n",
    "            is_match = (src_pre.shape == src_post.shape and \n",
    "                        src_pre.crs == src_post.crs and \n",
    "                        np.allclose(np.array(src_pre.transform), np.array(src_post.transform), atol=1e-8))\n",
    "            # Check if both rasters are perfectly aligned spatially by comparing their Affine transforms.\n",
    "            # We use np.allclose with a small tolerance (1e-8) instead of strict equality (==) \n",
    "            # to account for potential floating-point rounding errors during geoprocessing.\n",
    "            \n",
    "            if not is_match:\n",
    "                print(f\"[SKIP] Pair {i+1}: Geometric mismatch between pre and post rasters.\")\n",
    "                continue\n",
    "\n",
    "            # 2. Compute absolute difference\n",
    "            # S1 imagery: we typically use the absolute difference of backscatter/textures\n",
    "            diff_img = src_pre.read().astype(np.float32) - src_post.read().astype(np.float32)\n",
    "            \n",
    "            diff_images.append(diff_img)\n",
    "            print(f\"[INFO] Pair {i+1} processed successfully.\")\n",
    "            \n",
    "    return diff_images\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "# list_raster_pairs = [(\"pre_1.tif\", \"post_1.tif\"), (\"pre_2.tif\", \"post_2.tif\")]\n",
    "# diffs = compute_raster_differences(list_raster_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c55ce",
   "metadata": {},
   "source": [
    "# Mahotas functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e77c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MAHOTAS ##########\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import mahotas as mh  # mahotas not present in vigisar environment, add it manually with conda install mahotas\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def _compute_all_haralick_for_band(band_data: np.ndarray, window_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes 13 Haralick textures AND keeps the original band data.\n",
    "    Returns a stack of 14 layers (1 original + 13 textures).\n",
    "    \"\"\"\n",
    "    h, w = band_data.shape\n",
    "    pad = window_size // 2\n",
    "    # Pre-allocate 14 layers: layer 0 is original, layers 1-13 are textures\n",
    "    final_stack = np.zeros((14, h, w), dtype='float32')\n",
    "    final_stack[0] = band_data # Keeping the original band\n",
    "\n",
    "    # 1. Handle NaNs and identify valid data (mask pixel = True if NaN)\n",
    "    mask = np.isnan(band_data)\n",
    "    \n",
    "    # 2. Robust Min-Max Scaling to 0-255\n",
    "    # We calculate min/max only on valid pixels to avoid NaN interference\n",
    "    if np.any(~mask):  # np.any(~mask) = True if at least one pixel not NaN\n",
    "        b_min = np.nanmin(band_data)\n",
    "        b_max = np.nanmax(band_data)\n",
    "        \n",
    "        # Avoid division by zero if the image is constant\n",
    "        if b_max > b_min:\n",
    "            # Linear stretch: (x - min) / (max - min) * 255\n",
    "            clean_band = np.nan_to_num(band_data, nan=b_min)\n",
    "            band_uint8 = ((clean_band - b_min) / (b_max - b_min) * 255).astype(np.uint8)\n",
    "        else:\n",
    "            band_uint8 = np.zeros((h, w), dtype=np.uint8)\n",
    "    else:  # if no valid pixel, all the textures are just NaN images \n",
    "        return np.full((14, h, w), np.nan, dtype='float32') # 14 because original band is NaN as well\n",
    "\n",
    "    # 3. Padding and Sliding Window\n",
    "    padded = np.pad(band_uint8, pad, mode='reflect')  # adding pixels on the edges for the sliding window\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if mask[i, j]:\n",
    "                final_stack[1:, i, j] = np.nan # if pixel not valid, NaN on all textures\n",
    "                continue\n",
    "            \n",
    "            window = padded[i : i + window_size, j : j + window_size] # small window around the original image (i,j) pixel in the padded image\n",
    "            try:\n",
    "            # Compute the 13 Haralick features for the current window.\n",
    "            # mahotas returns a (4, 13) matrix corresponding to 4 directions (0°, 45°, 90°, 135°).\n",
    "            # We take the mean across axis 0 to obtain rotation-invariant descriptors.\n",
    "            # This ensures forest textures remain consistent regardless of the sensor's/trees' orientation.\n",
    "                features = mh.features.haralick(window).mean(axis=0)\n",
    "                final_stack[1:, i, j] = features\n",
    "\n",
    "            except:\n",
    "             # Mathematical edge cases (e.g., a window with constant values) can cause Haralick failures.\n",
    "            # Specifically, Correlation might be undefined if the standard deviation is zero.\n",
    "            # We default to 0 to prevent the entire processing pipeline from crashing \n",
    "            # We can't ask mahotas to calculate everything but correlation, it's made to calculate everything at once\n",
    "                final_stack[1:, i, j] = 0\n",
    "                \n",
    "    return final_stack\n",
    "\n",
    "\n",
    "def generate_full_haralick_stack(\n",
    "    input_stack: np.ndarray, \n",
    "    profile: dict, \n",
    "    window_size: int = 7\n",
    ") -> tuple[dict, np.ndarray, list[str]]:\n",
    "    \"\"\"\n",
    "    Generates a massive stack containing the original band \n",
    "    plus its 13 textures for every input band.\n",
    "    \"\"\"\n",
    "    n_bands = input_stack.shape[0]\n",
    "    haralick_names = [\n",
    "        \"ASM\", \"Contrast\", \"Correlation\", \"Variance\", \"IDM\", \n",
    "        \"SumAvg\", \"SumVar\", \"SumEnt\", \"Entropy\", \"DiffVar\", \n",
    "        \"DiffEnt\", \"IMC1\", \"IMC2\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Generating 14 layers (1 Original + 13 Textures) for each of the {n_bands} bands...\")\n",
    "\n",
    "    # Parallelize the computation across all available CPU cores (n_jobs=-1)\n",
    "    # to drastically reduce processing time for large S1 scenes\n",
    "    # Each band is processed independently to generate its own 13 Haralick textures\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(_compute_all_haralick_for_band)(input_stack[b], window_size) \n",
    "        for b in range(n_bands)\n",
    "    )\n",
    "    \n",
    "    # Concatenate all groups: Result shape (126, H, W)\n",
    "    full_output = np.concatenate(results, axis=0)\n",
    "    \n",
    "    # Generate labels: Band_Original, Band_ASM, Band_Contrast...\n",
    "    labels = []\n",
    "    original_labels = [\"G0_VH\", \"G0_VV\", \"q\", \"RVI\", \"DPSVI\", \"RFDI\", \"C_VH\", \"C_VV\", \"Cq\"]\n",
    "    for b_label in original_labels:\n",
    "        labels.append(b_label) # Add original band name\n",
    "        for h_label in haralick_names:\n",
    "            labels.append(f\"{b_label}_{h_label}\") # Add texture names\n",
    "            \n",
    "    # Update profile count to 126 bands\n",
    "    new_profile = profile.copy()\n",
    "    new_profile.update({\n",
    "        'count': full_output.shape[0],\n",
    "        'dtype': 'float32',\n",
    "        'nodata': np.nan\n",
    "    })\n",
    "    \n",
    "    return new_profile, full_output, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geo)",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
